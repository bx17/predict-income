{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过机器学习模型预测收入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集来自[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Census+Income)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from IPython.display import display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"census.csv\")\n",
    "display(data.head(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "年收入大于/小于5万的人及比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records = data.shape[0]\n",
    "n_greater_50k = (data['income'] == '>50K').sum()\n",
    "n_at_most_50k = (data['income'] != '>50K').sum()\n",
    "greater_percent = n_greater_50k / n_records*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据切分成`特征`和`标签`\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 归一化数字特征\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "features_raw[numerical] = scaler.fit_transform(data[numerical])\n",
    "\n",
    "display(features_raw.head(n = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pd.get_dummies(features_raw)\n",
    "income = income_raw.replace({'<=50K': 0, '>50K': 1})\n",
    "encoded = list(features.columns)\n",
    "print (\"{} total features after one-hot encoding.\".format(len(encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混洗和切分数据\n",
    "现在所有的 _类别变量_ 已被转换成数值特征，而且所有的数值特征已被规一化。和我们一般情况下做的一样，我们现在将数据（包括特征和它们的标签）切分成训练和测试集。其中80%的数据将用于训练和20%的数据用于测试。然后再进一步把训练数据分为训练集和验证集，用来选择和优化模型。\n",
    "\n",
    "运行下面的代码单元来完成切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, income, test_size = 0.2, random_state = 0,\n",
    "                                                    stratify = income)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0,\n",
    "                                                    stratify = y_train)\n",
    "\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Validation set has {} samples.\".format(X_val.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初步模型的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_val, y_val): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_val: features validation set\n",
    "       - y_val: income validation set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    start = time()\n",
    "    learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time()\n",
    "    \n",
    "    results['train_time'] = end - start\n",
    "\n",
    "    start = time()\n",
    "    predictions_val = learner.predict(X_val)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time()\n",
    "    \n",
    "    results['pred_time'] = end - start\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "    results['acc_val'] = accuracy_score(y_val, predictions_val)\n",
    "    results['f_train'] = fbeta_score(y_true=y_train[:300], y_pred=predictions_train, beta=0.5)\n",
    "    results['f_val'] = fbeta_score(y_true=y_val, y_pred=predictions_val, beta=0.5)\n",
    "       \n",
    "    print (\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf_A = DecisionTreeClassifier(random_state=16)\n",
    "clf_B = SVC(kernel='rbf', random_state=16)\n",
    "clf_C = AdaBoostClassifier(random_state=16)\n",
    "\n",
    "\n",
    "samples_1 = int(len(y_train) * 0.01)\n",
    "samples_10 = int(len(y_train) * 0.1)\n",
    "samples_100 = len(y_train)\n",
    "\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "        results[clf_name][i] = train_predict(clf, samples, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "clf = AdaBoostClassifier(random_state=16)\n",
    "parameters = {'n_estimators':[10, 50, 100, 150, 200, 300]}\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "best_clf = grid_obj.best_estimator_\n",
    "\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_val)\n",
    "best_predictions = best_clf.predict(X_val)\n",
    "\n",
    "print (best_clf)\n",
    "print (\"\\nUnoptimized model\\n------\")\n",
    "print (\"Accuracy score on validation data: {:.4f}\".format(accuracy_score(y_val, predictions)))\n",
    "print (\"F-score on validation data: {:.4f}\".format(fbeta_score(y_val, predictions, beta = 0.5)))\n",
    "print (\"\\nOptimized Model\\n------\")\n",
    "print (\"Final accuracy score on the validation data: {:.4f}\".format(accuracy_score(y_val, best_predictions)))\n",
    "print (\"Final F-score on the validation data: {:.4f}\".format(fbeta_score(y_val, best_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果:\n",
    " \n",
    "| 评价指标         |  未优化的模型        | 优化的模型        |\n",
    "| :------------: |  :---------------: | :-------------: | \n",
    "| 准确率          | 0.8648                   | 0.8722                |\n",
    "| F-score        | 0.7443                    | 0.7559                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该模型的表现随着弱分类器的数量（在10到300的范围内）的增加而提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择\n",
    "并**只使用五个最重要的特征**在相同的训练集上训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "# 减小特征空间\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_val_reduced = X_val[X_val.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "clf_on_reduced = (clone(best_clf)).fit(X_train_reduced, y_train)\n",
    "\n",
    "reduced_predictions = clf_on_reduced.predict(X_val_reduced)\n",
    "\n",
    "print (\"Final Model trained on full data\\n------\")\n",
    "print (\"Accuracy on validation data: {:.4f}\".format(accuracy_score(y_val, best_predictions)))\n",
    "print (\"F-score on validation data: {:.4f}\".format(fbeta_score(y_val, best_predictions, beta = 0.5)))\n",
    "print (\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print (\"Accuracy on validation data: {:.4f}\".format(accuracy_score(y_val, reduced_predictions)))\n",
    "print (\"F-score on validation data: {:.4f}\".format(fbeta_score(y_val, reduced_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集上的测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO test your model on testing data and report accuracy and F score\n",
    "predictions_test = best_clf.predict(X_test)\n",
    "accuracy_score_test = accuracy_score(y_test, predictions_test)\n",
    "fbeta_score_test = fbeta_score(y_test, predictions_test, beta=0.5)\n",
    "print(\"Accuracy:\", accuracy_score_test)\n",
    "print(\"F-score:\", fbeta_score_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
